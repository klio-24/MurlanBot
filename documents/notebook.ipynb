{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just an idea to develop a systematic approach to Murlan, since there’s not much research on it.\n",
    "\n",
    "Main objectives:\n",
    "-\tDevelop an optimal Murlan strategy, which may involve machine intelligence\n",
    "-\tCreate a bot that can execute this strategy\n",
    "-\tCreate an online interface for people to play with it\n",
    "-\tWrite a report in overleaf detailing the process\n",
    "-  Post on linkedin\n",
    "\n",
    "To Do:\n",
    "-\tRead this https://www.pagat.com/docs/sps2172.pdf\n",
    "-\tRead about how Poker GTO works\n",
    "-\tRead about this poker bot https://www.science.org/doi/10.1126/science.aay2400, see if any of these things apply to you\n",
    "-\tamazon MLOps to obtain the players moves, continuously train the model and redeploy it \n",
    "-\thttps://www.youtube.com/watch?v=Bj6lC93JMi0 follow this tutorial for card website\n",
    "-\tthink about how to form the problem ML-wise, learn more about the ML side of things \n",
    "-\tthink about how to use tensors to store data \n",
    "-\twatch a video on how the best poker bot works \n",
    "-  ‘skipping’ is a strategy and so needs to be an output of the AI which can increase effectiveness of AI, but will skip for now\n",
    "-  is MurlanMind a better name?\n",
    "-\twatch a video on how the best go bot works (https://jonathan-hui.medium.com/alphago-how-it-works-technically-26ddcc085319 - read and fully understand this too) \n",
    "-\tthink about how youre going to do initial training, is it just going to be random games playing forever? How do you implement the rule set? Is there a way to warm start it to initially train the right patterns? \n",
    "-\tIf the AI wins it can determine the best card from 3-10 to give since at that point it has perfect information (implement this later on - not needed for Minimum Viable Product)\n",
    "-\tit needs to have a memory to know what cards have been played, what cards could be played \n",
    "-\ton the website add a display that shows how many times its won and lost\n",
    "-\tfind the fastest way to implement the front end, some type of script framework (just make it functional not fancy) \n",
    "-\thave a rule-based approach to compare it to \n",
    "-\thttps://www.catsatcards.com/Games/Murlan.htm lay out rules in the report in a logical way\n",
    "-\tUse Pytorch\n",
    "-  create a script for a bot which selects a random move for self-training\n",
    "-\thttps://www.youtube.com/watch?v=IQLkPgkLMNg&ab_channel=Wanieru \n",
    "-\tInstall CUDA\n",
    "http://karpathy.github.io/2019/04/25/recipe/\n",
    "-\tSomeone says that a weakness to ISMCTS (information set monte carlo tree searchs) is processing time – here domain knowledge could be used to guide the AI down the right path\n",
    "-\tSo in second game, lets say opponent has two jokers, that needs to be in the AI’s knowledge base\n",
    "-\tMaybe you could have your normal algorithm, and after a set amount of cards have been played, you switch to normal monte carlo search with backpropagation and all of that\n",
    "-\tAlso the neural net needs to take into account how many cards left in the opponents hand (or maybe you do the game from the video where the guy says 'one of the few times I taught a class' to determine the best approach to take). in that case you would have to develop code to determine the full tree, I'm assuming the possible games played is still massive in the second round but nothing insanely large - in this portion of the calculation you could exploit algorithms to be computationally efficient even if the AI portion is weaker if not non-existent in the second round\n",
    "-  Check that when given a full deck, 'possible_moves_for_hand' calculates 119,302,085\n",
    "-\tWould be interesting to see if the right ‘behaviours’ emerge from self-learning, e.g. putting your highest card down when you've got two cards left\n",
    "-  based on 3b1b videos I'll have to try create examples to produce a loss function, e.g. for the 2 card each situation I make the AI output example to be the higher card\n",
    "-  what type of activation function do I do to prevent output being a non-valid response? (many places mentioning policy network)\n",
    "\n",
    "I think the overall neural net structure will be like:\n",
    "-\t54 input rows 1 or 0 do you have that card or not\n",
    "-\t54 entries does your opponent have that card (imperfect distribution, becoming more perfect as match goes on, and knowledge is perfect in that round)\n",
    "-\t54 entries what card is on the ‘table’ (all 0 when it’s a free turn)\n",
    "The above entries fully encapsulate the current state of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Possible moves:</b>\n",
    "- Single – 54\n",
    "- Double – 52 cards, 6 for each suit, (4C2) x 13 = 78\n",
    "- Triple – 4C3  x 13 = 52\n",
    "- Quadruple – 13\n",
    "\n",
    "total possible moves without straights:\n",
    "\n",
    "197\n",
    "\n",
    "Straight:\n",
    "5 cards to 13 cards, cant cycle to 3\n",
    "13P5*4^5 + 13P6^6 + … = 119301120\n",
    "\n",
    "TOTAL = 119301317\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "based on that 'I created an AI to play this card game because my friends dropped out video', a crude evaluation function could be total rank value of cards in hand, BUT THEN HOW DO YOU TAKE INTO ACCOUNT STRAIGHTS/TRIPLES - SEE HOW POKER DOES IT."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
