{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall process:\n",
    "-\tMake simple game simulation, where the bot just plays heuristically doing the lowest possible move\n",
    "-\tCreate an ML model for optimal play\n",
    "-\tMake a website that allows you to play the game with a mouse, and the bot’s moves are demonstrated too\n",
    "-\tHost the game on microservices\n",
    "-\tWrite report, cleanup github\n",
    "-\tPost linkedin\n",
    "\n",
    "To Do:\n",
    "-\tRead this https://www.pagat.com/docs/sps2172.pdf\n",
    "-\tRead about how Poker GTO works\n",
    "-\tRead about this poker bot https://www.science.org/doi/10.1126/science.aay2400, see if any of these things apply to you\n",
    "-\tamazon MLOps to obtain the players moves, continuously train the model and redeploy it \n",
    "-\thttps://www.youtube.com/watch?v=Bj6lC93JMi0 follow this tutorial for card website\n",
    "-\tthink about how to use tensors to store data \n",
    "-\twatch a video on how the best poker bot works \n",
    "-\twatch a video on how the best go bot works (https://jonathan-hui.medium.com/alphago-how-it-works-technically-26ddcc085319 - read and fully understand this too) \n",
    "-\tit needs to have a memory to know what cards have been played, what cards could be played \n",
    "-\ton the website add a display that shows how many times its won and lost\n",
    "-\thttps://www.catsatcards.com/Games/Murlan.htm lay out rules in the report in a logical way\n",
    "-\thttps://www.youtube.com/watch?v=IQLkPgkLMNg&ab_channel=Wanieru \n",
    "-\tInstall CUDA\n",
    "-   http://karpathy.github.io/2019/04/25/recipe/\n",
    "-\tWould be interesting to see if the right ‘behaviours’ emerge from self-learning, e.g. putting your highest card down when you've got two cards left\n",
    "-  based on 3b1b videos I'll have to try create examples to produce a loss function, e.g. for the 2 card each situation I make the AI output example to be the higher card\n",
    "-  what type of activation function do I do to prevent output being an illegal response? (many places mentioning policy network) https://costa.sh/blog-a-closer-look-at-invalid-action-masking-in-policy-gradient-algorithms.html\n",
    "-  https://www.youtube.com/watch?v=EB-NJtNERBQ - main example for MCTS\n",
    "-  https://www.youtube.com/watch?v=62nq4Zsn8vc the guy said the way you train your policy network is to train it to give the same outputs as your MCTS???\n",
    "To add later:\n",
    "- determine optimal card to give for second round if AI wins\n",
    "- implement quads\n",
    "- implement straights\n",
    "- implement a probability of winning at each turn just like alphago\n",
    "- skipping turn as a strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Possible moves:</b>\n",
    "- Single – 54\n",
    "- Double – 52 cards, 6 for each suit, (4C2) x 13 = 78\n",
    "- Triple – 4C3  x 13 = 52\n",
    "- Quadruple – 13\n",
    "\n",
    "total possible moves without straights:\n",
    "\n",
    "197\n",
    "\n",
    "Straight:\n",
    "5 cards to 13 cards, cant cycle to 3\n",
    "13P5*4^5 + 13P6^6 + … = 119301120\n",
    "\n",
    "TOTAL = 119301317\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "based on that 'I created an AI to play this card game because my friends dropped out video', a crude evaluation function could be total rank value of cards in hand, BUT THEN HOW DO YOU TAKE INTO ACCOUNT STRAIGHTS/TRIPLES - SEE HOW POKER DOES IT."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
